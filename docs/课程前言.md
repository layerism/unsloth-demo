# 课程前言

## 课程目标
1. 了解大模型发展趋势和相关原理
2. 掌握微调训练能应用何种场合（角色扮演），Supervised FinTuning (SFT)，DPO（直接偏好对齐）
3. 掌握 LoRA 的高效微调（低秩微调方案）
4. 自己完成数据集的获取和清洗（hugginface，modelscope）
5. 训练的调参和监控（tmux + swanlab）
6. checkpoint testing（例如：训练角色扮演，然后测试数学，编程，通用推理）
7. vllm 进行部署（sglang 和 vllm，openai 协议兼容的），chattool 连接上去，进行聊天 


## 课程使用的训练框架
注意：千万不要自己安装环境
1. unsloth（单卡王者，课程的选型），候选：llama-factory（分布式，写个配置就行），HF（方便科研），verl（强化学习，GRPO）

